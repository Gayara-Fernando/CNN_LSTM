{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f653664-0111-4023-bffc-da10ff3e8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebdae1f-2519-4292-a5ff-42b2c7320604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the data?\n",
    "\n",
    "# Let's do everything frrom scratch, so that we know what we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98d930d-2306-4101-9072-f9211ba7393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Bayesian task point us towards this location\n",
    "\n",
    "# Train data locations\n",
    "block_0101 = '../../../Spring_2024/S_lab_TasselNet/Block_1_TN/Block_1_images_and_xml'\n",
    "block_0102 = '../../../Spring_2024/S_lab_TasselNet/Block_2_TN/Block_2_images_and_xml'\n",
    "block_0203 = '../../../Spring_2024/S_lab_TasselNet/Block_9_TN/Block_9_images_and_xml'\n",
    "block_0301 = '../../../Spring_2024/S_lab_TasselNet/Block_13_TN/Block_13_images_and_xml'\n",
    "\n",
    "# train_blocks = [block_0101, block_0102, block_0203, block_0301]\n",
    "\n",
    "# valid data location\n",
    "block_0204 = '../../../Spring_2024/S_lab_TasselNet/Block_10_TN/Block_10_images_and_xml'\n",
    "\n",
    "# valid_blocks = [block_0204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3eff1e-6005-454a-b9c0-0bb8287e0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we do the preprocessing for one block first, and then repeat it for the rest? May be write a function for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c334116-4cde-493d-b18f-4a2d84dc75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider the block 0101\n",
    "block_0101_list = os.listdir(block_0101)\n",
    "block_0101_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b512f4e-0a93-4282-9ce7-af7cc90ab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from this list, we will only cosider the last 20 time points\n",
    "\n",
    "# first separate the xml and jpeg files\n",
    "\n",
    "# xml files\n",
    "xml_files = [file for file in block_0101_list if file.split('.')[-1] == 'xml']\n",
    "xml_files.sort()\n",
    "\n",
    "# jpeg files\n",
    "jpeg_files = [file for file in block_0101_list if file not in xml_files]\n",
    "jpeg_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69111f5e-bcac-4042-84d6-2cfda6f55434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only the final 20 items of the list -  we are only interested in the final 20 as they are the only ones in the same horizontal direction - meaning capturing the same field over time\n",
    "\n",
    "chosen_xml_files = xml_files[-20:]\n",
    "chosen_jpeg_files = jpeg_files[-20:]\n",
    "\n",
    "# make sure the xml and jpeg files correspond to each other?\n",
    "np.mean([file.split('.')[0] for file in chosen_xml_files] == [file.split('.')[0] for file in chosen_jpeg_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c4e966-7991-4e90-8db2-f5181a02ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have these in a function for future blocks\n",
    "\n",
    "def chose_xml_and_jpeg(file_location):\n",
    "    # list all files in location\n",
    "    list_of_all_files = os.listdir(file_location)\n",
    "    # sort files\n",
    "    list_of_all_files.sort()\n",
    "    # separate xml and jpeg files\n",
    "    all_xml_files = [file for file in list_of_all_files if file.split('.')[-1] == 'xml']\n",
    "    all_jpeg_files = [file for file in list_of_all_files if file not in all_xml_files]\n",
    "    # get the final 20 files\n",
    "    chosen_xml_files = all_xml_files[-20:]\n",
    "    chosen_jpeg_files = all_jpeg_files[-20:]\n",
    "    # make sure the xml and jpeg files correspond to each other?\n",
    "    mean = np.mean([file.split('.')[0] for file in chosen_xml_files] == [file.split('.')[0] for file in chosen_jpeg_files])\n",
    "\n",
    "    return(chosen_xml_files, chosen_jpeg_files, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5845713f-ad6d-4f26-8eed-f09416abc7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if this works\n",
    "try_for_blk1 = chose_xml_and_jpeg(block_0101)\n",
    "try_for_blk1[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
